- GAME CHANGERS: ARTIFICIAL INTELLIGENCE PART II, ARTIFICIAL INTELLIGENCE AND THE FEDERAL GOVERNMENT
[House Hearing, 115 Congress]
[From the U.S. Government Publishing Office]
GAME CHANGERS: ARTIFICIAL INTELLIGENCE PART II, ARTIFICIAL INTELLIGENCE
AND THE FEDERAL GOVERNMENT
=======================================================================
HEARING
BEFORE THE
SUBCOMMITTEE ON
INFORMATION TECHNOLOGY
OF THE
COMMITTEE ON OVERSIGHT
AND GOVERNMENT REFORM
HOUSE OF REPRESENTATIVES
ONE HUNDRED FIFTEENTH CONGRESS
SECOND SESSSION
__________
MARCH 7, 2018
__________
Serial No. 115-66
__________
Printed for the use of the Committee on Oversight and Government Reform
[GRAPHIC NOT AVAILABLE IN TIFF FORMAT]
Available via the World Wide Web: http://www.fdsys.gov
http://oversight.house.gov
__________
U.S. GOVERNMENT PUBLISHING OFFICE
30-297 PDF
WASHINGTON : 2018
-----------------------------------------------------------------------------------
For sale by the Superintendent of Documents, U.S. Government Publishing Office,
http://bookstore.gpo.gov. For more information, contact the GPO Customer Contact Center,
U.S. Government Publishing Office. Phone 202-512-1800, or 866-512-1800 (toll-free).
E-mail, [emailÂ protected]
Committee on Oversight and Government Reform
Trey Gowdy, South Carolina, Chairman
John J. Duncan, Jr., Tennessee
Elijah E. Cummings, Maryland,
Darrell E. Issa, California
Ranking Minority Member
Jim Jordan, Ohio
Carolyn B. Maloney, New York
Mark Sanford, South Carolina
Eleanor Holmes Norton, District of
Justin Amash, Michigan
Columbia
Paul A. Gosar, Arizona
Wm. Lacy Clay, Missouri
Scott DesJarlais, Tennessee
Stephen F. Lynch, Massachusetts
Blake Farenthold, Texas
Jim Cooper, Tennessee
Virginia Foxx, North Carolina
Gerald E. Connolly, Virginia
Thomas Massie, Kentucky
Robin L. Kelly, Illinois
Mark Meadows, North Carolina
Brenda L. Lawrence, Michigan
Ron DeSantis, Florida
Bonnie Watson Coleman, New Jersey
Dennis A. Ross, Florida
Stacey E. Plaskett, Virgin Islands
Mark Walker, North Carolina
Val Butler Demings, Florida
Rod Blum, Iowa
Raja Krishnamoorthi, Illinois
Jody B. Hice, Georgia
Jamie Raskin, Maryland
Steve Russell, Oklahoma
Peter Welch, Vermont
Glenn Grothman, Wisconsin
Matt Cartwright, Pennsylvania
Will Hurd, Texas
Mark DeSaulnier, California
Gary J. Palmer, Alabama
Jimmy Gomez,California
James Comer, Kentucky
Paul Mitchell, Michigan
Greg Gianforte, Montana
Sheria Clarke, Staff Director
William McKenna General Counsel
Troy Stock, Information Technology Subcommittee Staff Director
Sarah Moxley, Senior Professional Member
Sharon Casey, Deputy Chief Clerk
David Rapallo, Minority Staff Director
------
Subcommittee on Information Technology
Will Hurd, Texas, Chairman
Paul Mitchell, Michigan, Vice Chair
Robin L. Kelly, Illinois, Ranking
Darrell E. Issa, California
Minority Member
Justin Amash, Michigan
Jamie Raskin, Maryland
Blake Farenthold, Texas
Stephen F. Lynch, Massachusetts
Steve Russell, Oklahoma
Gerald E. Connolly, Virginia
Greg Gianforte, Montana
Raja Krishnamoorthi, Illinois
C O N T E N T S
----------
Page
Hearing held on March 7, 2018....................................
1
WITNESSES
Mr. John O. Everett, Ph.D., Deputy Director, Information
Innovation Office, Defense Advanced Research Projects Agency,
U.S. Department of Defense
Oral Statement...............................................
3
Mr. Keith Nadasone, Deputy Assistant Commissioner, Acquisition,
Information Technology Category Acquisition Management, U.S.
General Services Administration
Oral Statement...............................................
4
Written Statement............................................
7
Mr. James F. Kurose, Ph.D., Assistant Director, Computer and
Information Science, and Engineering, National Science
Foundation
Oral Statement...............................................
13
Written Statement............................................
15
Mr. Douglas Maughan, Ph.D., Division Director, Cybersecurity
Division, Homeland Security Advanced Research Projects Agency,
U.S. Department of Homeland Security
Oral Statement...............................................
27
Written Statement............................................
29
APPENDIX
Representative Gerald E. Connolly Statement......................
50
GAME CHANGERS: ARTIFICIAL INTELLIGENCE PART II, ARTIFICIAL INTELLIGENCE
AND THE FEDERAL GOVERNMENT
----------
Wednesday, March 7, 2018
House of Representatives,
Subcommittee on Information Technology,
Committee on Oversight and Government Reform,
Washington, D.C.
The subcommittee met, pursuant to call, at 2:03 p.m., in
Room 2154, Rayburn House Office Building, Hon. Will Hurd
[chairman of the subcommittee] presiding.
Present: Representatives Hurd, Mitchell, Amash, Farenthold,
Kelly, Lynch, Connolly, and Krishnamoorthi.
Mr. Hurd. The Subcommittee on Information Technology will
come to order. And without objection, the chair is authorized
to declare a recess at any time.
Good afternoon. Welcome to the Oversight and Government
Reform hearing on artificial intelligence. This is the second
hearing in a series of hearings on artificial intelligence, and
this series is an opportunity for the subcommittee to take a
deep dive into this issue.
I have three main objectives when it comes to AI in
government. First, it should make every interaction an
individual has with the Federal Government take less time, cost
less money, and be more secure. I have wonderful caseworkers on
staff who spend their time working to help constituents receive
their veterans' benefits or to help with Social Security. They
are speaking every day with people who are frustrated with how
long it takes to resolve problems in the Federal Government. I
believe with the adoption of AI, we can improve the response
time and, in some cases, prevent these problems in the first
place.
Second, AI should produce efficiencies and cost savings
that will help us do more for less money and help to provide
better, more transparent citizen-facing services. This should
help to restore the bonds of trust between citizens and their
governments. We have innovative companies, brilliant minds,
hardworking people, and the rule of law. So we, the United
States, should lead on AI, and the Federal Government needs to
be an active participant. Whether it is through basic and
applied research and development that DARPA, NSF, and DHS are
doing, or GSA's work on procurement, the AI within the
government needs to benefit those whom the government serves.
I thank the witnesses for being here today, and I look
forward to the hearing and learning from all of you. And I will
be honest, at the beginning of this endeavor I was prepared to
see not much use of AI throughout the Federal Government, and I
think our panelists here today are going to show how we are
doing some very interesting things in the government.
Mr. Hurd. And, as always, it is an honor to explore these
very important issues in a bipartisan fashion with my friend
and ranking member, the one and only Robin Kelly from Illinois.
Ms. Kelly. Thank you, Mr. Chairman.
Mr. Chairman, thank you for calling today's important
hearing on Federal agencies' adoption of artificial
intelligence, or AI. This is the second hearing in a three-part
series of hearings on AI. Today's hearing focuses on the
Federal Government's adoption of this technology.
AI has the potential to make government more efficient and
decrease costs across agencies. To fully realize the benefits
of AI, the U.S. must maintain its leadership role in promoting
technological innovation, yet preserving the United States'
leadership role in technologies like AI will require robust
Federal funding for research and development.
But at our first hearing on AI, Intel's chief technology
officer for AI warned us that, quote, ``Current Federal funding
levels are not keeping pace with the rest of the industrialized
world.'' In fact, President Trump's proposed budget for fiscal
year 2019 cuts or flattens nonmilitary agency budgets for R&D.
[Slide.]
Ms. Kelly. As you can see on the screens, the trend is so
clear that the National Science Board and the National Science
Foundation believe that China will surpass the United States in
R&D investments by the end of this year. The chart displayed
demonstrates China's rapidly growing investment and the U.S.
ceding its position as a leader in AI.
The future of U.S. innovation is at stake. This should be a
cause of concern for everyone. Outside of the Department of
Defense, the President's budget proposes an overall cut to
research and development of 21.2 percent. Consider, for
example, the National Science Foundation whose investments in
R&D have led to innovations that improve our everyday life.
From Google to Lasik eye surgery to cloud computing all can be
traced to NSF investments in technology.
[Slide.]
Ms. Kelly. This chart shows President Trump's precipitous
drop in nondefense R&D spending. In an agency like the National
Science Foundation which supports basic research in colleges
and universities and in the private sector, this budget
represented almost a 29 percent decrease from the agency's
actual spending levels in 2017. These budget cuts take the
United States in the wrong direction.
Another troubling trend for the U.S. is that we are not
making the critical investments today to educate the workforce
we need to sustain these industries of the future.
[Slide.]
Ms. Kelly. The displayed chart shows a number of science
and engineering undergraduates in China compared to the United
States. As you can see, we are not keeping pace with China,
which is displayed in red.
Yet another troubling factor is this administration's
hostility to immigrants. Until recently, the U.S. was able to
attract Ph.D. students from other countries to help supplement
the domestic workforce. The New York Times reported last year
that not only is Google opening AI innovation hubs in Canada
because of concerns with American immigration policies but that
the U.S. has already turned away promising people in the AI
field. Unfortunately, this administration's science,
immigration, and education policies are all working together to
reduce the U.S. lead in AI technologies. I hope today we can
discuss the policies and funding necessary to ensure we remain
competitive in this area.
Again, I thank you, Mr. Chairman, for having this hearing.
Mr. Hurd. Thank you.
And I am pleased now to introduce our witnesses. Our first
is Dr. John Everett. He is the deputy director of the
Information Innovation Office for DARPA. Mr. Keith Nakasone, he
is the deputy assistant commissioner for the Office of
Information Technology Category for the Federal Acquisitions
Service at GSA. Say that three times fast. Dr. James Kurose is
the assistant director for Computer and Information Science and
Engineering at National Science Foundation. It is always a
pleasure to have you here, sir. And last but not least, Dr.
Douglas Maughan is the division director of the Cybersecurity
Division in the Homeland Security Advanced Research Project
Agency at DHS.
Welcome to you all. And pursuant to committee rules, all
witnesses will be sworn in before you testify, so please rise
and raise your right hand.
[Witnesses sworn.]
Mr. Hurd. Thank you. Please let the record reflect that all
witnesses answered in the affirmative.
In order to allow time for discussion, please limit your
testimony to five minutes. Your entire written statement will
be made part of the record. And as a reminder, the clock in
front of you shows the remaining time you have. It is going to
turn yellow when you have 30 seconds left, and when it flashes
red, that means your time is up. And also remember to press the
button to turn your microphone on before speaking.
Now, I would like to recognize Dr. Everett for your five
minutes of opening remarks.
WITNESS STATEMENTS
STATEMENT OF JOHN O. EVERETT
Mr. Everett. Good afternoon, Chairman Hurd, Ranking Member
Kelly, and distinguished members of the committee. I appreciate
the invitation to give testimony on the state of AI research
today. My name is John Everett, and I'm the deputy director of
the Information Innovation Office at the Defense Advanced
Research Projects Agency, DARPA.
DARPA's mission is to create and prevent technological
surprise. We do so by funding research programs, each with a
specific goal to advance the state of the art in a particular
area. This strategy has served the country well by leveraging
academia and industry R&D labs to develop the enabling
technologies for new defense capabilities and to plant the
seeds for new industries such as the internet and self-driving
cars.
Since the 1960s, we have funded more than 50 programs in
AI. AI technologies have developed in two waves. The first wave
focused on abstract logic and reasoning tools that require
explicit representations of knowledge in the form of
handcrafted rules. The second wave, machine learning, uses
algorithms to extract implicit representations of knowledge
from large amounts of data.
The first wave started in the 1950s and explored many hard
problems in reasoning, understanding natural language, and
robotics. It produced many algorithms that are in common use
today such as planning and scheduling systems.
Researchers quickly discovered the importance of world
knowledge in solving problems and created expert systems that
use rules to represent knowledge about a particular subject
area such as diagnosing infectious diseases. An early DARPA-
funded expert system rivaled human performance in this area.
However, as we all know, for every rule, there's an exception,
and the work necessary to capture sufficient knowledge proved
impractical in many cases.
The second wave started in the 1990s in reaction to the
difficulty of capturing world knowledge by writing it down. The
most successful form of machine learning today is called the
neural network because it is inspired by the structure of the
human brain. Machine learning uses large amounts of data to
train an algorithm to do a specific task such as recognize
speech, drive a car, or search for pictures of, say, people
playing frisbee on a beach. However, these algorithms cannot
explain their conclusions, which makes them hard to trust.
Also, researchers have shown that sometimes imperceptible
changes to an input image, say, of a panda, can cause the
algorithm to confidently misclassify it as a monkey.
Nonetheless, the second wave of AI has yet to crest, and
researchers will continue to improve the technology and develop
interesting and innovative applications. We believe that the
next wave of AI will combine insights from the first and second
waves to produce systems that are aware of context so they can
interact more effectively with people. This will require major
advances in commonsense reasoning and natural language
processing.
Context in--is the shared understanding that people have
with each other and enables highly concise communication
through speech, intonation, facial expressions, and gestures.
Such communication is extremely difficult for current
algorithms to understand, making this an ideal area for DARPA
research. Thank you.
Mr. Hurd. Thank you, sir.
Mr. Nakasone, you are now recognized for five minutes.
STATEMENT OF KEITH NAKASONE
Mr. Nakasone. Good afternoon, Chairman Hurd, Ranking Member
Kelly, and members of the subcommittee. Thank you for the
opportunity to appear before you today. My name is Keith
Nakasone, and I am the deputy assistant commissioner for
acquisition operations in the Office of Information Technology
Category at GSA. I've been a participant in the growth of
emerging technologies in government over the past 20 years,
including during my years at the Defense Department.
Mr. Chairman, at the first hearing in this series you
stated that it was your hope agencies would use today's
discussion to inform Congress how we plan to use artificial
intelligence to spend taxpayer dollars wisely and make each
individual's interactions with government more efficient,
effective, and secure.
I would like to discuss four ways in which our agency is
supporting government AI evaluation and adoption to accomplish
that. First, our Federal Acquisition Service provides
contracting vehicles and mechanisms, including Schedule 70, as
well as several other governmentwide acquisition contracts,
which encourage competition and help connect agencies and
businesses to allow government to efficiently procure the most
effective new AI services and capabilities. GSA's IT Schedule
70 contracts provides Federal, State, local, and tribal
government agencies with access to over 7.5 million best-value
IT and telecommunications products, services, and solutions for
more than 4,600 pre-vetted vendors, including firms whose
offerings use AI and similar technologies.
Since emerging technology businesses frequently tend to be
startups, Schedule 70 offers two shortcuts, Startup
Springboard, and FastLane, as part of the Making It Easier
initiative, which aims to streamline the process for younger
innovative companies and suppliers to do business with
government.
Second, GSA is piloting robotic process automation and
related technologies designed to augment our workforce and
achieve more with less while establishing a foundation for
greater data-driven decision-making through AI.
GSA has developed a new pilot using AI for prediction of
regulatory compliance, the solicitation review tool uses
natural language processing, text mining, and machine learning
algorithms to substantially alleviate the human resources
needed to identify, audit, and enforce compliance of
solicitations posted on FBO.gov.
Further, GSA recently launched two pilots exploring the use
of robotic process automation and distributed ledger
technology, foundational technologies that can open our
programs to better decision-making through AI. These pilots aim
to increase GSA's operational efficiency, reduce costs, improve
processes, increase accuracy, and redeploy staff to higher-
value functions.
Third, our interagency Emerging Citizens Technology Office
unites more than 2,000 government managers from over 300
Federal, State, and local agencies and representatives from
businesses, startups, and research and civic organizations to
support and coordinate governmentwide development of citizen-
facing AI and other emerging technology programs, including
through resources at Emerging.Digital.gov. Recent initiatives
include the launch of an interagency venture capital advisory
group and a new education and training pilot.
Fourth, along with our private sector and Federal agency
partners, we are pursuing a greater understanding alignment of
ID modernization through cloud adoption, data services, and
emerging technologies, including AI, that deliver the greatest
benefit to the American people. For instance, through Data.gov
and ECTO, we are learning how to improve the standardization
and accessibility of government open data to help fuel
innovation. We have solicited input from industry partners on
how to improve data hosting so data sets are more easily
digestible for AI and machine learning.
GSA is essentially a shared service, and we are constantly
seeking ways to develop government faster, better, and smarter.
AI is a tool that can expand the value proposition for Federal
agencies, vendors, and the American people alike.
Thank you again for the opportunity to testify. I look
forward to your questions.
[Prepared statement of Mr. Nakasone follows:]
[GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
Mr. Hurd. Dr. Kurose, you now have five minutes.
STATEMENT OF JAMES F. KUROSE
Mr. Kurose. Thank you very much. Good afternoon, Chairman
Hurd, Ranking Member Kelly, and members of the subcommittee. My
name is Jim Kurose. I'm the assistant director at the National
Science Foundation for the Directorate of Computer and
Information Science and Engineering.
As you know, NSF contributes to national security and
economic competitiveness by supporting fundamental research in
all areas of science and engineering, as well as education for
the next generation of discoverers. I welcome this opportunity
to highlight NSF's AI investments.
Federal investments in foundational AI research are
critical to achieving and sustaining U.S. science and
technology leadership. Fundamental AI R&D challenges can be
broadly classified into two categories. First, there's narrow
AI that is focused on solving specific tasks in well-defined
domains such as speech recognition or image classification.
Here, NSF-funded researchers have pioneered new machine-
learning techniques and applied these techniques, for example,
to analyze breast cancer and predict sepsis.
To your opening remarks, Chairman Hurd, NSF is piloting the
use of AI clustering techniques in its own business processes
to help program managers select proposal reviewers.
The second broad category, general AI, is about
transferring what is learned in one setting to another and
ultimately appreciating intent, meaning, and understanding.
Several witnesses in your earlier panel have noted that these
goals remain an AI grand challenge in which we're also
investing.
In fiscal year 2017, the National Science Foundation
invested more than $120 million in core AI research. AI will
continue to be an important part of our research portfolio,
including NSF's Big Ideas. Indeed, NSF Director Dr. France
Cordova, my boss, recently described AI as, quote, ``the
universal connector that interweaves all of our big ideas. Data
science is changing the very nature of scientific inquiry, and
AI's use of data has the potential to revolutionize everything
we do in science.
The AI innovations that we are seeing today are built on
earlier fundamental research. For example, NSF's investments in
reinforcement learning decades ago are enabling today's deep
learning systems in autonomous vehicles. As Eric Schmidt,
former Google Alphabet CEO, has said NSF is, quote, ``where all
interesting research gets started.'' Well, you know, yes, we're
a starter, but we're also more than that. We're part of the
larger very uniquely American research and innovation ecosystem
among academia, industry, and government with the flow of
ideas, artifacts, and people across these sectors. This
ecosystem has given rise to multibillion-dollar industries
including AI, but truly, it all begins with investment in
fundamental long-term research often made with Federal research
dollars.
At NSF, we're constantly exploring new partnership models
to grow this ecosystem. We've partnered with industry on joint
research solicitations. Recently, we combined $50 million from
the National Science Foundation with an equivalent amount from
an industry consortium to advance wireless technologies. These
public and private partnerships serve as models for potential
future AI R&D collaborations.
Federal agencies like my colleagues here are other
partners. NSF co-chairs the Networking and Information
Technology Research and Development Subcommittee of the
National Science and Technology Council, and we co-chaired an
NST committee that developed the 2016 National AI R&D Strategic
Plan.
You've heard that much of the AI revolution has been
enabled by the availability of large data sets in computing.
NSF has invested in open training data sets and is committed to
public access to data resulting from federally funded research.
NSF has also long invested in high-performance computing. To
complement these investments, we recently announced a
partnership with three commercial cloud providers--Amazon,
Google, and Microsoft--to make $12 million in cloud resources
available to academic researchers through our BIGDATA program.
Beyond data and computation, there remains the most
valuable resources of all: people. NSF investments here include
research that builds the foundations for rigorous, engaging
computer science education at all levels, K through 12,
university, and lifelong learning. For example, working with
the teaching community and many partners, NSF's support led to
a new advanced placement computer science principal's course
whose launch last year was the largest ever in the College
Board's history. More than 50,000 students took the exam. We
saw remarkable strides in participation of groups long
underrepresented in computing as well. More than double the
number of African Americans, Hispanics, and women took this new
AP exam in 2017 as compared to the existing CS AP exam the year
before.
NSF's investments and partnerships have helped sustain the
Nation's leadership in AI and enhanced our nation's economic
competitiveness and security. We at the NSF are committed to
continuing this investment in fundamental AI research,
infrastructure, and workforce to maintain U.S. global
leadership.
This concludes my remarks, and thank you again for the
opportunity to address this subcommittee.
[Prepared statement of Mr. Kurose follows:]
[GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
Mr. Hurd. Thank you, sir.
Dr. Maughan, you are now recognized for five minutes.
STATEMENT OF DOUGLAS MAUGHAN
Mr. Maughan. Chairman Hurd, Ranking Member Kelly, and
members of the subcommittee, good afternoon, and thank you for
this opportunity today.
I will be sharing important aspects of how the Department
of Homeland Security's Science and Technology Directorate, or
S&T as it is known, is using artificial intelligence-based
technologies in research and development and working across all
DHS mission areas to integrate innovative technologies into
everyday use.
As the R&D arm of DHS, S&T develops the tools,
technologies, and knowledge products for DHS operators and
State and local first responders, ensuring the R&D coordination
across the Department to develop solutions for the needs of
today and tomorrow.
S&T partners with Federal agencies, as Jim said, industry,
academia, and international government, to create and test
solutions that help the Nation's homeland security officials
prevent, respond to, and recover from all hazards and threats.
S&T's goal is to provide real-world solutions in a realistic
time frame.
AI offers much promise. From a government perspective, it
holds the potential for enhanced insight into public service
operations and improved delivery of citizen services. Examples
span the range from helping people navigate immigration systems
to predicting and preempting threats and enabling resilient
critical infrastructures that today are under attack.
AI technology is improving our knowledge and actions.
Fueled by sensors, data digitization, and ever-increasing
connectedness, AI filters, prioritizes, classifies, measures,
and predicts outcomes which can have significant impact on
people.
Private industry is leading the way in AI development
because many see its implementation as a key competitive
advantage. Government must be informed and ensure AI technology
is being used to create efficiencies and enhance the public
good.
At DHS S&T, AI is a part of several ongoing cybersecurity
division research initiatives, which are using AI and machine-
learning techniques for predictive analysis of malware
evolution against future malware variance; detecting anomalous
network traffic and behaviors to inform decision-making; and
helping identify, categorize, and score adversarial telephony
denial-of-service techniques. For example, S&T developed a
machine-learning-based policy engine capable of blocking more
than 120,000 calls per month, including robocalls. This same
technology can be used to defend 911 centers against life-
threatening distributed denial-of-service attacks.
DHS S&T also is working closely with the Nation's startups
on AI through our Silicon Valley Innovation Program, or SVIP.
Launched in 2015, the Department is connecting with innovation
communities across the Nation to harness the commercial R&D
ecosystem for technologies with government applications and
help accelerate transition to market with the goal of reshaping
how government entrepreneurs and industry work together to find
cutting-edge solutions for the Department operators.
SVIP and Customs and Border Protection are partnering on AI
and machine-learning topics, including visualization,
predictive models, and entity resolution and currently are
funding startups to exchange information on intelligence, build
capacity, and increase worldwide security and compliance
standards.
Looking forward in AI, DHS continues to support the design
of AI systems in a manner that makes the actions and decision-
making of technologists, government officials, and other users
both transparent and understandable. The design, development,
implementation, and evaluation of AI solutions should generate
trust that the government and industry are innovating
responsibly by demonstrating that the government is balancing
risks and delivering on its mission to serve the public fairly
and justly and influence responsible evolution and the role for
AI in the private sector.
In order for the government to be relevant in this fast-
moving and competitive future that is being defined by AI,
innovation should be advanced through an emphasis on
responsible R&D. In addition, AI R&D should involve multiple
disciplines and those perspectives that involve experts not
only from computer science but also the other physical and
social sciences.
Mr. Chairman and members of the subcommittee, AI is here to
stay. This reality means that S&T must aggressively work with
its research, development, test, and evaluation partners
throughout government and industry so homeland security
applications of AI and machine learning are both effective and
trusted.
Thank you for your thoughtful leadership on these issues. I
look forward to your questions.
[Prepared statement of Mr. Maughan follows:]
[GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
Mr. Hurd. Thank you, Dr. Maughan.
My first question to the panel, it is for all of you. And
you all are here as the representation of some of the best
things that are happening when it comes to AI across the
Federal Government. And one of the things that we heard in the
last panel and we have heard in conversation on this topic, two
things that the Federal Government can be doing: research
obviously, right, continued basic research, applied research
like some of the things that Dr. Maughan is doing at DHS. I am
in. We get it. We are going to try to figure out how to do
that, right? This is a bipartisan issue.
Second thing we have heard is also data, you know, how do
we unlock data that the Federal Government has that can be used
to train and teach these various algorithms. I get those two
things. But I am asking each one of you all--and this is not to
apply to just your agency but across the Federal Government,
what is one thing that the Federal Government should be doing
now in implementing artificial intelligence, something that is
available, something that can be used that we should be doing?
Is that a fair question? Dr. Maughan, you are shaking your
head. Yes, Dr. Maughan?
Mr. Maughan. Sure. So, I mean, we--things we are doing
already include, as I mentioned with our Customs and Border
Protection folks, they have something called the Global Travel
Assessment System, GTAS, which they make available to all of
our international partners as well. And we have been working
with them to add in capability into that open-source system
that are AI-based. And so we're starting to see that roll out
as new capability for not only CBP but all of our international
partners.
Mr. Hurd. Dr. Kurose?
Mr. Kurose. Well, thank you. And thank you for mentioning
the importance of funding basic research and open data as well.
You know, I had mentioned in my own testimony about what
the National Science Foundation is doing testing the use of
some AI techniques actually built with open software on making
recommendations for panelists for program managers. And it's an
example of the broader challenge, I think, and opportunity of
adopting AI tools and having folks in government use AI tools
to help inform decision-making that they are. It's not going to
be a magic press-the-button-and-get-the-answer-out but using
that to help complement already-existing activities.
Dr. Nakasone, maybe a more specific question for you, you
mention 7.5 million different kinds of applications and tools
that GSA makes available. Are there tools that other agencies
are not taking advantage of and they should when it comes to
this topic?
Mr. Nakasone. So when we speak about the 7.5 solution sets
that we're talking about, you know, it crosses the scope of
telecommunications, IT services, supplies, commodities, right?
So we have access and we are learning every day on how to build
these solution sets by looking at use cases, best practices,
and things like with of course the working groups that we have
to understand how we can deliver these broader acquisition
solutions to cover, you know, things like distributed ledger
technology with the robotic process automation and the--and --
--
Mr. Hurd. So let me ask it this way. We bring in a lot of
Federal CIOs when we go through the FITARA scorecard talking
about how are they modernizing their digital infrastructure.
Give me a question I should be asking them, you know? Are you
using--fill in the blank.
Mr. Nakasone. Right. So what--you know, something that we
could be asking is what emerging technologies are you using to
do your IT modernization uplift? You know, we recently have--
GSA has a big part in the IT modernization plan, and I think
one of the things that we need to look at is how are we
leveraging emerging technologies and injecting it into our
infrastructure.
Mr. Hurd. Dr. Everett, wrap it up for us.
Mr. Everett. I think there's a temptation to think of AI as
magic and as being able to solve all our problems. When you
talk about implementing something that would be effective for
the Federal Government, I think we should take the perspective
of first understanding what the actual problems are and then
working our way back towards how AI could actually address
those problems and not just up front but looking at what is the
lifecycle cost of implementing those technologies.
Mr. Hurd. Thank you, Dr. Everett.
The gentlewoman from Illinois is now recognized.
Ms. Kelly. Thank you, Mr. Chair.
I think we all agree that research and development is
essential to continuing to improve the government's use of
artificial intelligence, and in my opening statement I talked
about the concern about China passing us by. Are there any
other countries that you think are putting a lot of money into
research and development and are passing us by or could pass us
by when it comes to AI? Whoever wants to answer.
Mr. Everett. The one that I hear about all the time is
China. Certainly the international community, however, is very
broad, and the AI community started out internationally in
1970, so the basis for the technology is international. Whether
or not that is an issue at the individual country level I don't
know, aside from China.
Ms. Kelly. All right.
Mr. Kurose. I would again just add I think it is
international, so absolutely the comments that you had made in
your opening statements about China I note that DeepMind that
Google has acquired is from the U.K., that Microsoft acquired a
really topflight AI research company from Canada. And so really
it's a global phenomenon.
Ms. Kelly. And I think we all would agree that funding is
extremely important so that you can continue the good work that
you're already doing, and we can progress further.
The other question is, besides funding, finding people that
are educated and trained to help us progress in this area and
what are suggestions that you have on what we can do to find
people interested in the field that want to get involved in the
field.
Mr. Maughan. So my suggestion is we need to make--so at the
core of AI is computer science, and so it's making computer
science attractive and so the--again, depending upon the
application area, cybersecurity, which is what some of us work
on, is one of the most attractive but we're still not
attracting as many as we need. So we have to find those things
that make it exciting. We've been, for example, funding
competitions, high school and collegiate competitions as a way
to try to get students interested in cybersecurity and computer
science as early as possible, and I think we just need to
continue to push that agenda earlier in the school system. The
sooner we can get youth interested in computer science as a
career, they use the tools all day anyway, so let's teach them
that there's a career in that direction.
Ms. Kelly. I know when you--the statistic I showed, it is
amazing the difference between us and China, people in the
field and the Ph.D.'s graduating.
Mr. Kurose. So I'd like to second Doug's recommendation
about the focus on pipeline and also the importance of a broad
computer science education. In my testimony I had mentioned the
computer science principal's AP exam and how popular that has
been. There are other investments that the National Science
Foundation is making in exploring computer science in the
middle schools. I think at the undergraduate level also
computer science now is becoming a much more popular major and
also programs such as what's called Computer Science Plus X, so
it's the application of computing in other disciplines and two
grand challenges and two challenges that the country faces, and
there's also a movement afoot of AI Plus X, so applying AI and
data science for good.
So I think at both the high school and the undergraduate
level that, you know, there are programs afoot and universities
innovating in that space. At the Ph.D. level we always face a
challenge in that keeping Ph.D. students in academia. There are
lots of interesting challenges to be addressed in industry, and
it's important to keep our Ph.D. pipeline cranking at full
speed as well.
Mr. Nakasone. So I guess one thing that GSA focuses on, you
talked about recruiting, and we actively search out, go to
universities, and also when we look at the diversity aspects,
we are, you know, recruiting from minority perspective.
I just want to say for GSA's overall workforce, you know,
40 percent are minorities and 46 percent are female. And within
the IT field, we have 39 percent that are minorities and 33
percent that are female, so, you know, we work hard to try to
recruit talented and the best of the ability to try to get
highly educated people into the workforce. And we have to--as
we build out these emerging technology solution sets, I think
by showing us--or we Federal Government agencies need to figure
out how to get that message out there that, no kidding, we are
leaning forward and building out and using emerging technology
solutions.
Ms. Kelly. How much do you rely on--do you think AI relies
on students educated outside of the United States to supplement
the workforce? Whoever wants to answer. You can answer.
Mr. Nakasone. Sorry.
Ms. Kelly. Don't be shy.
Mr. Nakasone. As far as that, I don't have that data in
front of me, but however, we can take that back as a question.
Ms. Kelly. Okay.
Mr. Hurd. The distinguished gentleman from the great State
of Michigan is now recognized for his first round of questions.
Mr. Mitchell. Thank you, Mr. Chairman.
I think one of the issues that has arisen as we look at
adoption of AI and expansion of it is really getting a broader
understanding of what it is and how impacts our lives
currently. I have read a couple of articles recently where it
seems to me to be an innate fear of what AI is. How do we at
the Federal level overcome or get the level of understanding
among the population as a whole, not the tech weenie
population. They all think it is cool. It is the other folks
about what AI is, how it makes decisions, and why it is of
value to them if we are going to continue to expand investment
and get more people into training. Anybody who wants to tackle
that, please go ahead. Mr. Maughan, you smile and chuckle. You
are going to pass it off to Dr. Kurose?
Mr. Maughan. I am waiting to see if Dr. Kurose wants to go
first.
Mr. Kurose. Actually, I'm very happy to go first. It's a
really great question, and it really comes to the question of
decision-making and, you know, there's--there have been
computer software-assisted decision-making for a long period of
time. And when we do predictions, we do regression analysis.
So, I mean, these are--there's a long history of relying on
computation to help in making decisions. And I think the key
phrase that you mentioned is AI making decisions. And in the
end it needs to be people making decisions, and it needs to be
people making decisions with AI software.
Mr. Mitchell. How do we get enough transparency of how that
happens so that people understand that in the real world
outside of here and a handful of other places? How do we
achieve that? Because we need to do that if we are going to get
the level of acceptance and engagement and education that we
want. How do we achieve that, folks?
Mr. Kurose. Right, well, so I agree 100 percent. It's
absolutely a question of outreach. I think with some AI
techniques that are in use today there's an issue of
explainability, which I think Dr. Everett and DARPA's had a
program on explainability of AI, so maybe I could pass it down
to my right.
Mr. Mitchell. Ping-pong. Go ahead, Dr. Everett.
Mr. Everett. We are just starting a new program called
Explainable AI, and it directly addresses the issue that a lot
of the machine-learning software that we have today cannot
explain why it has ----
Mr. Mitchell. Right.
Mr. Everett.--come up with a particular answer, and so the
objective of the research is to say tell me why you think this
is a certain kind of bird, and it will tell you, well, I think
it's got a red crest and a black stripe on the wing, and then
it will show you that it is actually looking at the right part
of the image to start to build trust.
Another aspect of this is assuring autonomous systems. So
we have an autonomous ship called Sea Hunter, and to make it--
to ensure that it would operate safely within shipping lanes,
for example, it has to pass the commercial collision ----
Mr. Mitchell. Right.
Mr. Everett.--regulations. So we're looking at ways in
which to do--to use mathematical techniques to verify that the
software will behave as expected in a wide range of
circumstances that it might encounter in the real world.
Mr. Mitchell. You're not likely to get beyond an autonomous
ship in the near future, Doctor, but I have to be honest, how
soon would that research and that information become available
to the population at a broader level do you think?
Mr. Everett. I think it will diffuse rather slowly,
particularly as the popular culture tends to portray AI with a
mix of science and science fiction.
Mr. Mitchell. Yes. And evil at some level or fear of evil.
Let's put it that way. But let me get to my second question as
time is running a little short. What is your agency's approach
in dealing with a difficult question of ethics in the use of
AI, which kind of goes to what you are suggesting? How are you
approaching that with the general population or even within
your agency?
Mr. Maughan. Certainly, I think that in the case of the
research piece, we need to look at that. As I mentioned in my
testimony, you need to make sure that the--kind of the AI
itself is transparent and understandable and you can actually
see the decisions being made are balancing risks and are fair
and just to the recipient of those, and that requires us to
have not only the AI piece of it but kind of watching the AI.
How do I ensure that the AI is working and doing what it wants?
I think we're still early in the day, but certainly agree that
the ethics question was raised in your industry panel as well.
Mr. Mitchell. Anybody else have any input? Go ahead, sir.
Mr. Kurose. Yes, I'd like to say that I think the ethics
question is also often very tied up with data and how data is
used in inferences from data. It's an active research area. NSF
is funding a number of activities there. I think it also calls
to the front the importance of interdisciplinary collaboration
here because it's not just computer scientists and engineers.
It's also social, behavioral, and economic scientists who have
to be involved in this as well.
Mr. Mitchell. I appreciate it. My time is expired. Thank
you, Mr. Chair.
Mr. Hurd. The distinguished gentleman from the Commonwealth
of Massachusetts is now recognized for his five minutes.
Mr. Lynch. Thank you very much, Mr. Chairman, and to
Ranking Member Kelly for your persistent attention on something
I think that should be a huge priority for both Democrats and
Republicans in this Congress.
I do want to note that Ms. Kelly in her opening remarks had
put up a good slide there that demonstrated that the Chinese
recent announcement--or in the last few years announcement on
AI, their intense focus and funding on that, you know, has them
eclipsing the U.S. investment not only because of their
additional funding but because the Trump administration has
backed off somewhat on research and development funding for a
number of our agencies. I know that NSF is looking at a cut in
funding of I think $9 billion, and I know that DHS as well.
Especially in your Science and Technology Directorate, you are
looking at I think it is a $1.3 billion cut.
So I am concerned about whether we are recognizing the
priority with our budget as well. And, you know, you have been
very helpful in terms of demonstrating the importance of this
issue, but do you see any need for additional funding? And
also, you know, Dr. Everett and Mr. Nakasone, you see this as
well. I know that DARPA has been considering projects from
companies in my district from, you know, underwater radar
systems to, you know, enhanced antibiotics, you know, for use
against these resistant strains of bacteria to climate change.
And so we really do need, as Dr. Kurose has said, an
interdisciplinary approach, but all of that is affected by the
amount of available dollars for research and development.
And we have had such great success in the past through NASA
and other agencies where basically nondefense research has
really helped us enormously across society. And I am just
wondering, Dr. Everett or any of you, for the whole panel, do
you see that the lack of funding here could trip up or
basically prevent some of the wonderful discoveries and
advancements that we anticipate in this field?
Mr. Everett. Well, DARPA supports the President's budget
request for our agency. We are a projects-based agency. Our
projects last roughly four years. Our PMs are not civil service
but rather they come from industry and academia for a limited
period of time. So what that means is that every year 25
percent of our programs are turning over, 25 percent of our PMs
are new. This enables us to rapidly shift our budget to meet
current priorities that we see emerging in the technology
space.
Mr. Lynch. Okay. Do you have any opinions about the
National Science Foundation or any part of HHS that also might
benefit from further funding or are we just talking about
DARPA?
Mr. Everett. I'm speaking for DARPA.
Mr. Lynch. Okay. All right. We have got other witnesses as
well. Mr. Nakasone?
Mr. Nakasone. Sure. Thank you for your question. When it
comes to funding, as far as GSA is concerned, you know, I just
want to thank Emily Murphy, who is our new GSA administrator,
and Alan Thomas, who's our FAS commissioner, and Kay T. Ely,
who I work under, supports the efforts on the distributed
ledger technology and the robotic process automation and ----
Mr. Lynch. I am sorry. You are eating all my time.
Mr. Nakasone. Yes, sir.
Mr. Lynch. I can't go with this. In English, do you think
more money would help?
Mr. Nakasone. For--from a GSA perspective ----
Mr. Lynch. Well, that is who you represent.
Mr. Nakasone. Yes. I think ----
Mr. Lynch. Okay. That is good. Mr. Kurose? That is all I am
asking for.
Mr. Kurose. Thank you.
Mr. Lynch. Nothing complicated.
Mr. Kurose. Just to say that the President's fiscal year
2019 budget request with the addendum funding NSF at $7.5
billion, which is the '17-enacted level.
But to your question, I want to stress there is capacity to
do more. When I mentioned that the National Science Foundation
funds $122 million in AI core research, if we look at proposals
that were not funded but rated either competitive or highly
competitive, that's $174 million in proposals there, so there
is ----
Mr. Lynch. Okay.
Mr. Kurose.--capacity to do more.
Mr. Lynch. That is helpful. Thank you very much.
Mr. Chairman, I yield back.
Mr. Hurd. My esteemed colleague from the Commonwealth of
Virginia is now recognized.
Mr. Connolly. I thank you, Mr. Chairman. And by the way,
congratulations I think on your re-nomination last night,
right?
Mr. Hurd. That is right.
Mr. Connolly. All right. Let's stipulate you all support
the President's budget and it is perfect and you wouldn't
change a word or a number. Let's stipulate that so you don't
have to demonstrate any further loyalty. We got it. But let's
talk a little bit about the relationship between R&D and
technological innovation and its impact on the economy. And I
am particularly interested in Federal R&D.
So, Dr. Everett, there used to be something called
DARPANET, correct?
Mr. Everett. That's correct.
Mr. Connolly. And what is it called today?
Mr. Everett. The internet.
Mr. Connolly. The internet. So DARPANET, when we first--
when your agency was smart enough to make that critical
investment, were the commercial dollars flowing into that R&D
effort at the time?
Mr. Everett. No, certainly not.
Mr. Connolly. No. It was entirely a Federal R&D effort, is
that correct?
Mr. Everett. That's correct.
Mr. Connolly. And somewhere along the line someone decided
this is so nifty. This is so useful to us internally that maybe
it might have some other applications. Is that correct?
Mr. Everett. Yes. And I'd like to point out that it became
NSFNET before it became ----
Mr. Connolly. And then it became ----
Mr. Everett.--the internet.
Mr. Connolly.--NSFNET. Thank you very much. Good point. So
would that be the same story of GPS technology?
Mr. Everett. That would be.
Mr. Connolly. So GPS, which is now ubiquitous, we all take
it for granted, you can't even lie about getting lost going to
a meeting anymore, kind of put paper maps out of business. But
GPS was also a Federal R&D investment, is that correct?
Mr. Everett. That's correct.
Mr. Connolly. Your agency?
Mr. Everett. Yes.
Mr. Connolly. What about robotics? Did your agency get
involved in robotics at all?
Mr. Everett. We just concluded the DARPA robotics
challenge, so yes.
Mr. Connolly. Yes, so a lot of the research in robotics,
again a Federal investment, your agency being one of the
pioneers?
Mr. Everett. Yes.
Mr. Connolly. Drones, developed by the private sector or
was that a Federal R&D investment as well?
Mr. Everett. Initially, a Federal R&D.
Mr. Connolly. My goodness. What about noise cancelation
technologies?
Mr. Everett. I'm not directly familiar with that
technology.
Mr. Connolly. Well, for example, we did a lot--during the
Cold War, we did a lot of hush-hush work, no longer hush-hush,
on noise cancelation technologies for reasons you can surmise.
But after the Cold War when we were looking at civilian
application for R&D in our possession of the Federal
Government, we took noise cancelation out of your agency and
out of the Pentagon and we applied it to things like cars and
even other things like parts of a room that we could cancel
noise to allow privacy. We use it in courtrooms today. That all
came out of Federal R&D technologies for defense at the time.
Human genome, was that your area, Dr. Kurose, human genome
research?
Mr. Kurose. Excuse me, not my personal area of research,
but certainly bioinformatics and computation plays an
absolutely critical role there.
Mr. Connolly. But the Human Genome Project, so that was run
by some private entity in New York, right? Golly. It is not a
trick question, Dr. Kurose.
Mr. Kurose. Okay.
Mr. Connolly. The answer is of course not.
Mr. Kurose. Of course.
Mr. Connolly. It was a Federal ----
Mr. Kurose. Federal.
Mr. Connolly.--R&D investment. And I am trying to make a
point here. Now, there is a lot of loose talk about the
government can't do anything right. That is not true. You four
represent the face of the Federal Government that has
transformed the world with its R&D investment, and we are not
even talking pharmacological research. Almost all basic
research in pharmacological areas is Federal because the
private sector won't take the risk. And right now, we are
counting on the Federal Government to save us from antibiotic-
resistant bacteria that could unfortunately transform health
worldwide because it is not profitable for the private sector
to engage in that R&D right now, so we got to do it.
But we have transformed the world. So when we say we are
going to cut a couple of billion dollars out of Federal R&D and
I look at this record, I tremble at what are we cutting? Is it
the next GPS? Is it the next drone? Is it the next Human Genome
Project? Is it the next internet? We don't know. But the
opportunity cost I fear is enormous.
And so it may be that DARPA is happy with the budget it has
got, but this Member of Congress trembles at a 21 percent cut
that Ms. Kelly pointed out to us at the beginning in her
opening statement because there is an opportunity cost we can't
calculate. We can't even know for us. But I do know this:
Whatever amount of money we spent on DARPANET, it was worth
every cent. The return on that investment cannot be calculated.
And that is true for GPS, and that is true for drones, and it
is true for the Human Genome Project. These are investments
worth making. And America does not make itself great again when
it retreats from the field of R&D.
So thank you for being here and know that a number of us up
here are going to continue to push hard for your budgets for
the sake of the country. Thank you.
Mr. Hurd. Mr. Krishnamoorthi, you are now recognized.
Mr. Krishnamoorthi. Thank you, Mr. Chairman. Thank you,
Ranking Member Kelly. I really appreciate the opportunity to be
able to ask a few questions of our distinguished panel.
Last month, I, along with others, including my
distinguished colleague Paul Mitchell, who is on this
subcommittee, introduced a bill called the AI Jobs Act, which
basically requires for the first time that the Department of
Labor study the impact of artificial intelligence on our
workforce, you know, what areas of the economy are going to be
impacted the most? How do we prepare our workforce for this
artificial intelligence revolution and make sure that they are
ready to take advantage of it, as some of you have talked
about?
I wanted to just start out with Mr. Kurose. What specific
industries do you think are most likely to kind of experience
the impact of artificial intelligence in our economy?
Mr. Kurose. Well, thank you for your question and the
interest here. Actually, I want to do a short promo if I might
for National Academies study on information technology and the
U.S. workforce that came out just late last year and was funded
by the National Science Foundation. And it was actually written
both by economists. The committee that chaired this was an
economist Erik Brynjolfsson from MIT and the machine-learning
professor from Carnegie Mellon Tom Mitchell, and what I found
very interesting about this, to answer your question, is that
they talk about the broad application of IT technology and AI
technology specifically across the whole U.S. workforce. So
it's not so much a question of which jobs will be lost, which
jobs will be created but really how AI will transform work
across broad, broad swatches of the U.S. workforce and again
not just even in automation in terms of robots replacing jobs
but also AI's software helping doctors and lawyers and high-
cognitive-skilled jobs. And so I would recommend this to you
and to everybody, just very insightful report.
Mr. Krishnamoorthi. Right. Right. Well, thank you so much.
I don't know if robots will replace Members of Congress. We
might write a bill about that beforehand.
Mr. Lynch. Sounds good.
Mr. Krishnamoorthi. Well, I want to switch subjects to
something that Congresswoman Kelly brought up before, which I
thought it was really important which is kind of the rise of
China in the field of artificial intelligence. I want to ask
kind of the corollary set of questions, which is how do we
catch up and overtake them? What are our strengths in this area
that we need to leverage to basically come back and eclipse
them over the shorter long term? Dr. Everett, can you go for
it?
Mr. Everett. We have a very different system than China,
but I think we can leverage it. So, as Mr. Connolly pointed
out, a lot of the original investments came from DARPA and from
other parts of the DOD and the Federal Government that
ultimately led to inventions such as the cell phone. If we look
at the DARPA Grand Challenge, which in 2004 put up a $1 million
prize for an car to complete 132-mile course in the Nevada
desert driving autonomously, we then--no cars did, so we then
had a 2005 challenge. Five cars did at that time. That laid the
basis for the self-driving car industry. So I believe that we
are effective in de-risking technologies at the Federal level
so that we can then enable venture capitalists and well-funded
companies to take on the substantial business risk to bring
them to market and to make them reliable for consumers.
Mr. Krishnamoorthi. Mr. Nakasone?
Mr. Nakasone. Yes, thank you for the question. I think one
of the things we can do is do a lot of cross-collaboration,
leveraging the Emerging Citizens Technology Office to convene,
facilitate, collaborate, and help rapidly deploy and also from
an acquisitions standpoint is have this private-public
engagement and provide acquisition solutions so that we can
support the entire Federal, State, local government.
Mr. Krishnamoorthi. If I might add, it sounds like--I mean,
both your answers kind of include an element of the private
sector playing a substantial role in the development of
artificial intelligence. If I might, it sounds like one
strength we have is that we are not necessarily going to pick
and choose what is the best technology in any given sector of
artificial intelligence. We may let the best one bloom and then
the private sector helps to fuel it, whereas in China they
might kind of decide something is the best and it may not end
up being the best. Is that a fair point, Dr. Maughan? Do you
want to comment?
Mr. Maughan. Certainly. I believe, you know, let the market
decide. Let's let these new technologies come out that are AI-
based, and those that are successful in helping people in their
applications, they'll survive, and things that don't, they'll
die, right? So let the market decide.
Mr. Krishnamoorthi. Great. Thank you so much. Thank you.
Mr. Hurd. Mr. Mitchell.
Mr. Mitchell. Dr. Everett, you know, my colleagues left
unfortunately. I asked them to stay because I promised them it
would be interesting. I appreciate the new things I learn every
day as a new Member of Congress, better over 14 months. I found
out something new you just shared with me. So the internet was
invented by DARPA?
Mr. Everett. That's correct.
Mr. Mitchell. So it wasn't a former politician, formerly a
Vice President?
Mr. Everett. It might have been popularized by a former
politician.
Mr. Mitchell. Well, that helps a lot. I was confused about
that up until just a few moments ago.
A question for all of you, a serious question sort of and
sort of not, but I think I want to make a point. If I had a
magic wand and could invent a giant wad of cash, a big bushel
basketful of cash--around here, it would have to be $1,000
bills or something, maybe $1 million bills--are any of you
going to turn it down? Anybody here going to turn down more
money? No takers. Exactly my point, which is priorities have to
be made by your agencies, by the President of the United
States, by Congress in terms of how we prioritize funding to
get things accomplished on a broad range of things. And it is
not a bushel basket that suddenly regenerates cash or, as I
tell my teenage children, no, the cash tree out back is going
to be bare. It takes priorities. And at some point in time
there isn't enough cash sort of thing.
So I suggest that if people want to spend more on this--we
had a hearing this morning on transportation infrastructure on
the highways and putting more money in the Federal Highway
Trust Fund. Decisions have to be made where that cash comes
from, and I am hopeful that those concerns about artificial
intelligence or how we fund our highways, that discussions can
be held not just about how we either go further in debt or we
tax more, how we save some money and actually find a way to pay
for these things rather than expecting the American public to
just go deeper in debt or pay more taxes. I have not heard a
lot of that from some of my colleagues. He left. It is too bad.
So I appreciate your time, and I apologize for the little bit
snarky question, but I think it made the point. I appreciate
it. Thank you.
I yield back, Mr. Chair.
Mr. Hurd. Dr. Everett, you said earlier one of the things
we should be looking at in the Federal Government what is the
problem set that you have, what is the problem that you are
trying to solve, and maybe there are tools that use machine
learning or artificial intelligence. How do we get a senior
manager in the government in that mindset? Who would they go to
to say here is my problem; are there other tools that I should
be using to help improve citizen-facing services?
Mr. Everett. Well, that's a very broad question. And ----
Mr. Hurd. Does GSA have anything in their toolkit, the NSF
or DHS have a way or, you know, here are some potential tools
that could solve this problem that may or may not be being
used? Do we need folks within the government to better define
the problem set and maybe Dr. Maughan goes out and finds, you
know, some company that may be doing it and do some of that
applied research you guys are so good at? Is that how we should
be thinking about this problem, Dr. Everett?
Mr. Everett. Well, a few years ago we ran a program called
XDATA, and it was in the area of big data analytics. We open-
sourced much of the software that we developed there. That
software has subsequently been used by startups in the private
sector. IBM has made a major investment in Spark, which is a
big data platform. So this information that we--we have
published it and made it available to the private sector
directly. That doesn't get directly to your question but it
does at least start to enable the private sector to create
solutions in this area.
Mr. Hurd. Dr. Kurose?
Mr. Kurose. Within the National Science Foundation, we're
taking up a process of agency reform, and one of the pillars
there is making IT work for us. And so, for example,
understanding what are the open-source tools that we may be
able to combine to help us do our work more efficiently,
exactly what you were saying. The example that I mentioned
earlier about using AI clustering techniques to help program
managers actually identify the most appropriate--really the
best panelists and reviewers for proposals is one example of
that. So having those decisions made locally and knowing what's
available has proven to be very valuable.
Mr. Hurd. So if we had someone in the U.S. Census Bureau
that wanted to learn more, how would they do that?
Mr. Kurose. Well, for this particular project, we could
certainly put them in touch with people inside the NSF who are
working on this project.
Mr. Hurd. Dr. Maughan, it looks like you were getting ready
to say something.
Mr. Maughan. Well, I was just going to say that, you know,
when we talk to operators in the field and they're looking for
solutions, they don't necessarily say I need an AI solution to
my problem, right? They come to us and say I need a new widget
or a new this, but I--it looks like this, and then our job is
to go find the researchers at the universities or the companies
or--and a lot of it ends up being how they think about solving
it and do they think about solving it in an efficient manner
that can take advantage of new technologies? Because we are in
an innovative country, an innovative mindset, and I think
that's one of the benefits from an earlier question is we do
have an innovative community out there that really is trying to
bring cutting-edge solutions to the operations community. The
operations community don't know they need an AI-based solution,
but if you give them a solution that solves their problem, they
don't care if it's AI-based or not. They'll use it, they'll
deploy it, the companies can be successful.
Mr. Hurd. If we had Mr. Mitchell's cash tree and let's say
we had $100 million, in what kind of basic research should we
be putting that towards? And, Dr. Everett and Dr. Kurose, if
you had ----
Mr. Kurose. So I will say--and I will just echo what Doug
Maughan said. We have a very, very creative community, and many
of the best ideas are--they're bottom-up ideas, so we say to
the community, here are broad areas that are very important. I
might label a couple of grand--some of the grand challenges I
talked about earlier. Explainable AI, fairness, accountability,
transparency, and decision-making, for example, are all really,
really important areas. The ideas are going to come from the
research community itself.
Mr. Hurd. I think you referenced $145 million worth of
research proposals that you have been given that you haven't
been able to fund. I am assuming ----
Mr. Kurose. That's right, $174 million ----
Mr. Hurd. A hundred and seventy-four.
Mr. Kurose.--in artificial intelligence.
Mr. Hurd. Wow.
Mr. Kurose. Right.
Mr. Everett. So in our area we are more project-driven, so
we would have--reach out to the community to find people
interested in starting programs in the relevant areas. One area
that I think is very important for us to be looking at is
commonsense reasoning. That is what people are--it's--people
are so good at it, it's hard to even describe.
Mr. Hurd. I know some people that may need help with that.
Mr. Everett. Computers are definitely challenged in this
area, but if we're going to move past graphical interfaces with
computers where they're simply tools and computers are going to
become more active partners in decision-making, we're going to
need to imbue them with common sense.
Mr. Hurd. And my last question--and whoever would like to
answer it--what is the equivalent of going to the moon with
artificial intelligence? I will say this, it has been
interesting as we have been looking at this and talking to
folks--I went out on the plaza of the Capitol and asked people
what do you think about artificial intelligence? Is it good or
bad? I was shocked at how many people are scared of it. You
know, I think we have had too many movies where the robot with
the plastic face that is getting ready to snatch you, right?
You know, Will Smith. And so one of the things that we all
understand the importance of this, and I always--you know, if
Vladimir Putin said that whoever master's AI is going to be the
sole hegemon and we should listen, but to be able to explain
this in a way to folks that don't have you all's experience or
background, what is that moonshot in artificial intelligence,
Dr. Kurose?
Mr. Kurose. So maybe if I could start, I'd come back to
earlier in my testimony talking about narrow AI versus general
AI, and in narrow AI it's what we're hearing about, image
classification, speech understanding, phenomenal leaps forward
on that. But if you look at, for instance, what an 18-month-old
child can do and how the child can transfer learning from one
environment to another, how a child can understand intent and
meaning, that that's really the grand challenge. General AI
still remains a very grand challenge.
Mr. Everett. I would second that. Right now, we're building
tools, and the popular press makes it seem as if these are
going to become autonomous and think for themselves, but that
is very far from the actual case of things. Right now, we know
that people learn by having as few as one example, and yet we
need terabytes of data to get our systems to learn. We may look
back on this time as the era of incredibly inefficient machine
learning, so a moonshot might take us to the point where
computers actually do understand us in ways that our tools
today don't. But what we have today are tools.
Mr. Maughan. I would just add to something earlier said by
Dr. Everett, which is the program at DARPA, which is the
explainable AI, it may just be that the moonshot is AI that is
just in and around us all the time and we don't even think
about it. We don't call it AI; it just is, it works, and it
becomes part of our everyday life and we don't worry about it.
And that ----
Mr. Hurd. It is not locking us out of our house.
Mr. Maughan. It doesn't lock you out of the house, but it
might just be that explainable piece that might be the
moonshot.
Mr. Hurd. Excellent. Well, I appreciate that, Dr. Maughan.
I want to thank all the witnesses for appearing before us
today, and we are going to hold the record open for two weeks
for any member to submit an opening statement or questions for
the record.
And if there is no further business, without objection, the
subcommittee stands adjourned.
[Whereupon, at 3:13 p.m., the subcommittee was adjourned.]
APPENDIX
----------
Material Submitted for the Hearing Record
[GRAPHICS NOT AVAILABLE IN TIFF FORMAT]
[all]